{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPZPNLLE2DvQIGVftba0G78",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/huugod06/mlp-simple/blob/main/notebooks/mlp_simple.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0tQjtPeohdrC",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 595
        },
        "outputId": "aef069e8-0326-430c-b130-14915016da5d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Información del entorno\n",
            "------------------------------\n",
            "Nombre y apellidos: HUGO DE DIOS BASANTA\n",
            "Fecha: 2006-03-05\n",
            "Propósito: Entrenar un MLP simple sobre MNIST, medir accuracy y guardar el modelo.\n",
            "TensorFlow: 2.19.0\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "\u001b[1m11490434/11490434\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n",
            "Shapes -> X_train: (10000, 784) y_train: (10000,) | X_test: (2000, 784) y_test: (2000,)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │        \u001b[38;5;34m50,240\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)             │           \u001b[38;5;34m650\u001b[0m │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │        <span style=\"color: #00af00; text-decoration-color: #00af00\">50,240</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">650</span> │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m50,890\u001b[0m (198.79 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">50,890</span> (198.79 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m50,890\u001b[0m (198.79 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">50,890</span> (198.79 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.5724 - loss: 1.4814 - val_accuracy: 0.8920 - val_loss: 0.4532\n",
            "Epoch 2/5\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8851 - loss: 0.4328 - val_accuracy: 0.9170 - val_loss: 0.3354\n",
            "Epoch 3/5\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9114 - loss: 0.3197 - val_accuracy: 0.9200 - val_loss: 0.2960\n",
            "Epoch 4/5\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9269 - loss: 0.2682 - val_accuracy: 0.9230 - val_loss: 0.2729\n",
            "Epoch 5/5\n",
            "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9353 - loss: 0.2337 - val_accuracy: 0.9240 - val_loss: 0.2555\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test loss: 0.3395 | Test accuracy: 0.9015\n",
            "Modelo guardado en: /content/mlp_model.h5\n"
          ]
        }
      ],
      "source": [
        "# === Cabecera del experimento ===\n",
        "# Nombre y apellidos: HUGO DE DIOS BASANTA\n",
        "# Fecha: (se establece automáticamente abajo)\n",
        "# Propósito: Entrenar un perceptrón multicapa (MLP) para clasificar dígitos manuscritos (MNIST) y evaluar su rendimiento.\n",
        "\n",
        "import time\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "# Configuración y reproducibilidad\n",
        "np.random.seed(42)\n",
        "tf.random.set_seed(42)\n",
        "\n",
        "# Metadatos\n",
        "NOMBRE = \"HUGO DE DIOS BASANTA\"\n",
        "FECHA = \"2006-03-05\"\n",
        "PROPOSITO = \"Entrenar un MLP simple sobre MNIST, medir accuracy y guardar el modelo.\"\n",
        "\n",
        "print(\"Información del entorno\")\n",
        "print(\"-\" * 30)\n",
        "print(\"Nombre y apellidos:\", NOMBRE)\n",
        "print(\"Fecha:\", FECHA)\n",
        "print(\"Propósito:\", PROPOSITO)\n",
        "print(\"TensorFlow:\", tf.__version__)\n",
        "\n",
        "# ===== Carga y preprocesado de datos =====\n",
        "(X_train, y_train), (X_test, y_test) = keras.datasets.mnist.load_data()\n",
        "\n",
        "# (Opcional) Submuestreo para entrenamientos rápidos en Colab\n",
        "X_train, y_train = X_train[:10000], y_train[:10000]\n",
        "X_test, y_test   = X_test[:2000],  y_test[:2000]\n",
        "\n",
        "# Normalización a [0,1] y aplanado (28x28 -> 784)\n",
        "X_train = X_train.astype(\"float32\") / 255.0\n",
        "X_test  = X_test.astype(\"float32\")  / 255.0\n",
        "X_train = X_train.reshape((-1, 28 * 28))\n",
        "X_test  = X_test.reshape((-1, 28 * 28))\n",
        "\n",
        "print(\"Shapes -> X_train:\", X_train.shape, \"y_train:\", y_train.shape,\n",
        "      \"| X_test:\", X_test.shape, \"y_test:\", y_test.shape)\n",
        "\n",
        "# ===== Definición del modelo =====\n",
        "model = keras.Sequential([\n",
        "    layers.Input(shape=(784,)),\n",
        "    layers.Dense(64, activation=\"relu\"),\n",
        "    layers.Dense(10, activation=\"softmax\")\n",
        "])\n",
        "\n",
        "model.summary()\n",
        "\n",
        "# ===== Compilación =====\n",
        "model.compile(\n",
        "    optimizer=\"adam\",\n",
        "    loss=\"sparse_categorical_crossentropy\",\n",
        "    metrics=[\"accuracy\"]\n",
        ")\n",
        "\n",
        "# ===== Entrenamiento =====\n",
        "history = model.fit(\n",
        "    X_train, y_train,\n",
        "    validation_split=0.1,\n",
        "    epochs=5,\n",
        "    batch_size=128,\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "# ===== Evaluación =====\n",
        "test_loss, test_acc = model.evaluate(X_test, y_test, verbose=0)\n",
        "print(f\"Test loss: {test_loss:.4f} | Test accuracy: {test_acc:.4f}\")\n",
        "\n",
        "# ===== Guardado del modelo (Paso 12) =====\n",
        "save_path = \"/content/mlp_model.h5\"\n",
        "model.save(save_path)\n",
        "print(\"Modelo guardado en:\", save_path)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# === Generar informe Markdown ===\n",
        "import time\n",
        "\n",
        "# Capturar el summary del modelo\n",
        "summary_lines = []\n",
        "model.summary(print_fn=lambda x: summary_lines.append(x))\n",
        "summary_text = \"\\n\".join(summary_lines)\n",
        "\n",
        "# Datos del informe\n",
        "autor = \"HUGO DE DIOS BASANTA\"\n",
        "fecha_str = time.strftime(\"%Y-%m-%d %H:%M:%S\")\n",
        "\n",
        "report = f\"\"\"# Informe del experimento MLP\n",
        "**Autor:** {autor}\n",
        "\n",
        "## Arquitectura\n",
        "\n",
        "## Métricas finales\n",
        "- Test loss: {test_loss:.4f}\n",
        "- Test accuracy: {test_acc:.4f}\n",
        "\n",
        "## Fecha\n",
        "{fecha_str}\n",
        "\"\"\"\n",
        "\n",
        "# Guardar el archivo en /content\n",
        "with open(\"/content/report.md\", \"w\") as f:\n",
        "    f.write(report)\n",
        "\n",
        "print(\"Informe creado en /content/report.md\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "rNfRbYKHJYqS",
        "outputId": "f10da4b9-779a-4150-de49-05e8b5192feb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Informe creado en /content/report.md\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import hashlib, csv, time, os, json\n",
        "\n",
        "def sha256(path):\n",
        "    h = hashlib.sha256()\n",
        "    with open(path, \"rb\") as f:\n",
        "        for chunk in iter(lambda: f.read(1024*1024), b\"\"):\n",
        "            h.update(chunk)\n",
        "    return h.hexdigest()\n",
        "\n",
        "# Guarda una copia del notebook actual para hashearlo\n",
        "from google.colab import runtime\n",
        "# En Colab, descarga manualmente el .ipynb o usa:\n",
        "# Archivo -> Descargar .ipynb y súbelo como /content/mlp_simple.ipynb si quieres el hash exacto del repo.\n",
        "# Para seguir, creamos un marcador vacío si no lo tienes:\n",
        "if not os.path.exists(\"/content/mlp_simple.ipynb\"):\n",
        "    with open(\"/content/mlp_simple.ipynb\",\"w\") as f: f.write(\"{}\")\n",
        "\n",
        "hash_notebook = sha256(\"/content/mlp_simple.ipynb\")\n",
        "hash_model    = sha256(\"/content/mlp_model.h5\")\n",
        "hash_report   = sha256(\"/content/report.md\")\n",
        "\n",
        "print(\"SHA-256 notebook:\", hash_notebook)\n",
        "print(\"SHA-256 modelo  :\", hash_model)\n",
        "print(\"SHA-256 reporte :\", hash_report)\n",
        "\n",
        "with open(\"/content/ledger.csv\", \"w\", newline=\"\") as f:\n",
        "    w = csv.writer(f)\n",
        "    w.writerow([\"archivo\",\"hash\",\"timestamp\"])\n",
        "    w.writerow([\"notebooks/mlp_simple.ipynb\", hash_notebook, int(time.time())])\n",
        "    w.writerow([\"model/mlp_model.h5\",        hash_model,    int(time.time())])\n",
        "    w.writerow([\"docs/report.md\",            hash_report,   int(time.time())])\n",
        "\n",
        "print(\"Ledger: /content/ledger.csv\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JDpzP2YdWVfS",
        "outputId": "44bdc4f8-2bf1-4541-9421-30f03c009598"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SHA-256 notebook: 7d13938dc4970a0d7aed11034d7c74b49932df161f08326c2c5453d58fb446f9\n",
            "SHA-256 modelo  : eafdd7a923d1ea8ae8807afdd12bc02b3b9389b97d1c999e3a4965b5f3a8a0ba\n",
            "SHA-256 reporte : 7dd3a6dcc7139844307e36d17043a6486ea30bc01b425d68f08b475e7034410d\n",
            "Ledger: /content/ledger.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Reflexión final\n",
        "\n",
        "**Autor:** HUGO DE DIOS BASANTA  \n",
        "**Fecha:** {{pon aquí la fecha de hoy}}\n",
        "\n",
        "## ¿Qué he entendido del MLP?\n",
        "Un MLP (Perceptrón Multicapa) es una red neuronal feed-forward compuesta por capas: una de entrada, una o más **capas ocultas** con neuronas densas (p. ej., ReLU) y una **capa de salida** (p. ej., softmax para clasificación).  \n",
        "Aprende ajustando pesos mediante **backpropagation** y **descenso de gradiente** (optimizer Adam en este experimento).  \n",
        "En MNIST, aplanamos imágenes 28×28 → 784 características y el MLP aprende **representaciones no lineales** que separan las clases (dígitos 0–9). Aunque no explota la estructura espacial como una CNN, con un preprocesado simple puede alcanzar buenas **accuracies** en poco tiempo.\n",
        "\n",
        "## ¿Qué significa reproducibilidad?\n",
        "Reproducibilidad es poder **obtener los mismos resultados (o muy cercanos)** si alguien ejecuta el mismo código, con la misma configuración y datos.  \n",
        "Implica:\n",
        "- **Control de versiones** del código y de los artefactos (repo limpio).  \n",
        "- **Semillas** fijas (np/tf) y registros de hiperparámetros.  \n",
        "- Guardar dependencias/entorno (p. ej., versión de TensorFlow).  \n",
        "- **Trazabilidad** de los resultados (logs, métricas, informes).\n",
        "\n",
        "## ¿Qué aporta registrar hashes?\n",
        "Registrar **hashes SHA-256** de los archivos clave (notebook, modelo, informe) garantiza:\n",
        "- **Integridad**: si el archivo cambia, el hash ya no coincide.  \n",
        "- **Trazabilidad y auditoría**: podemos demostrar qué versión exacta generó ciertos resultados.  \n",
        "- **Reproducibilidad práctica**: comparar el archivo descargado desde GitHub con el `ledger.csv` confirma que trabajamos con la **misma** versión que se usó en el experimento.\n"
      ],
      "metadata": {
        "id": "lEqzWBmwWYj8"
      }
    }
  ]
}